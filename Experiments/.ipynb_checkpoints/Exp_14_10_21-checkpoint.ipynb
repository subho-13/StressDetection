{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d993b85-004f-4a10-a46a-ef05ad598ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.fft as fft\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from numpy import hamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a58f27-747e-421d-b9b3-48c7dcc3b36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../WESAD/'\n",
    "SUBJECTS = ['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '13', '14', '15', '16', '17']\n",
    "CHEST_SIGNALS = ['ECG', 'EMG', 'EDA', 'Resp', 'Temp', 'ACC']\n",
    "CHEST_SAMPLING_RATE = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfbf5fa-295f-4297-b676-a83c370b3c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_subject_data(subject) :\n",
    "    path = PATH + 'S' + subject + '/S' + subject + '.pkl'\n",
    "    subject = pd.read_pickle(path)\n",
    "    \n",
    "    return subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56073146-b544-476c-aa87-86a20d6e48e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_raw(signal, duration, sampling_rate, title) :\n",
    "    n = duration * sampling_rate\n",
    "    l = len(signal)\n",
    "    \n",
    "    s = random.randint(0, l - n)\n",
    "    df = pd.DataFrame(columns=['x', 'y'])\n",
    "    df['x'] = np.arange(n)\n",
    "    df['y'] = signal[s:s+n]\n",
    "    \n",
    "    plt.figure(figsize=(20, 5))\n",
    "    sns.scatterplot(x = 'x', y = 'y', data = df, s = 3, color='0').set(title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2fd307-cee2-4dea-8a95-713d97188b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the different chest signals\n",
    "SAMPLING_RATE = 700\n",
    "DURATION = 30\n",
    "\n",
    "subject = random.choice(SUBJECTS)\n",
    "subject_data = read_subject_data(subject)\n",
    "\n",
    "chest_signals = subject_data['signal']['chest']\n",
    "\n",
    "for signal_type in chest_signals :\n",
    "    if signal_type == 'ACC' :\n",
    "        continue\n",
    "    \n",
    "    signal = chest_signals[signal_type]\n",
    "    visualize_raw(signal, DURATION, SAMPLING_RATE, signal_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "019b54fd-e460-4288-8c29-6823535a061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://imotions.com/blog/eda/\n",
    "\n",
    "# https://www.scitepress.org/Papers/2021/102446/102446.pdf\n",
    "# https://sci-hub.ee/10.1016/j.cmpb.2020.105482\n",
    "WINDOW_LEN = 20\n",
    "OVERLAP = 0.75\n",
    "NUM_FEATURES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "6480a253-1215-42c1-823d-604d39bc123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the continuous intervals for each label\n",
    "def find_intervals(labels) :\n",
    "    intervals = []\n",
    "\n",
    "    l = len(labels)\n",
    "    i = 0\n",
    "    label = labels[0]\n",
    "\n",
    "    for j in range(l):\n",
    "        if label != labels[j]:\n",
    "            intervals.append({\n",
    "                'label' : label, \n",
    "                'beg' : i,\n",
    "                'end' : j\n",
    "                })\n",
    "            i = j\n",
    "            label = labels[j]\n",
    "\n",
    "    intervals.append({\n",
    "        'label' : label, \n",
    "        'beg' : i,\n",
    "        'end' : l\n",
    "    })\n",
    "\n",
    "    return intervals\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "64bd8ca9-e8c9-47e7-9ec9-2fad68b81375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fft_features(signal, num_features) :\n",
    "    window = hamming(len(signal))\n",
    "    signal *= window\n",
    "    coeffs = fft.fft(signal)\n",
    "    l = len(coeffs)\n",
    "    freqs = fft.fftfreq(l)\n",
    "    \n",
    "    # Discard the negative elems\n",
    "    l //= 2\n",
    "    amps = np.abs(coeffs[0:l])\n",
    "    freqs = np.abs(freqs[0:l])\n",
    "    \n",
    "    # Sort descending w.r.t amp   \n",
    "    p = amps.argsort()[::-1]\n",
    "    freqs = freqs[p]\n",
    "    amps = amps[p]\n",
    "    \n",
    "    features = [[amps[i], freqs[i]] for i in range(num_features)]    \n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "bd016944-ba02-4494-86c0-2e69923ce1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_fft_features(train_features, test_features) :\n",
    "#     feature_mean = np.mean(train_features, axis=0)\n",
    "    feature_std = np.std(train_features, axis=0)\n",
    "#     train_features -= feature_mean\n",
    "#     test_features -= feature_mean\n",
    "    train_features = np.divide(train_features, feature_std, out=np.zeros_like(train_features), where=feature_std!=0)\n",
    "    test_features = np.divide(test_features, feature_std, out=np.zeros_like(test_features), where=feature_std!=0)\n",
    "    \n",
    "    return train_features, test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "4c52300d-efc9-4a9f-831f-59bfe6659bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSIENT = 0\n",
    "BASELINE = 1\n",
    "STRESS = 2\n",
    "AMUSEMENT = 3\n",
    "MEDITATION = 4\n",
    "IGNORE = 5\n",
    "\n",
    "def extract_signal_features(signal, intervals, sampling_rate, window_len = WINDOW_LEN, overlap = OVERLAP, num_features = NUM_FEATURES) :\n",
    "    segment_size = sampling_rate * window_len\n",
    "    signal_features = {\n",
    "        BASELINE : [],\n",
    "        STRESS : [],\n",
    "        AMUSEMENT : [],\n",
    "        MEDITATION : []\n",
    "    }\n",
    "    \n",
    "    baseline_av = 0\n",
    "    \n",
    "    for interval in intervals :\n",
    "        label = interval['label']\n",
    "        beg = interval['beg']\n",
    "        end = interval['end']\n",
    "        \n",
    "        signal_of_interest = signal[beg:end]  \n",
    "        \n",
    "        if label >= IGNORE or label == TRANSIENT:\n",
    "            baseline_av = (np.mean(signal_of_interest) + baseline_av)/2\n",
    "            continue      \n",
    "            \n",
    "        if label == BASELINE :\n",
    "            baseline_av = (np.mean(signal_of_interest) + baseline_av)/2\n",
    "        \n",
    "        signal_of_interest -= baseline_av\n",
    "        \n",
    "        l = end - beg        \n",
    "        while l >= segment_size:\n",
    "            segment = signal_of_interest[int(l - segment_size) : l]\n",
    "            l -= int((1 - overlap) * segment_size)\n",
    "            \n",
    "            segment_features = extract_fft_features(segment, num_features)            \n",
    "            signal_features[label].append(segment_features)\n",
    "        \n",
    "    return signal_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "b633ee66-5c0c-47c4-b1d2-1ceba5c09559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chest_signal_dataset(subjects, signal_type) :\n",
    "    dataset = defaultdict(list)\n",
    "    for subject in subjects :\n",
    "        subject_data = read_subject_data(subject)\n",
    "        intervals = find_intervals(subject_data['label'])\n",
    "        \n",
    "        signal = np.array(subject_data['signal']['chest'][signal_type]).flatten()\n",
    "        \n",
    "        signal_features = extract_signal_features(signal, intervals, CHEST_SAMPLING_RATE)\n",
    "        \n",
    "        for label, feature_vecs in signal_features.items() :\n",
    "            dataset[label] += list(feature_vecs)\n",
    "            \n",
    "    features_dataset = [] \n",
    "    label_dataset = []\n",
    "    \n",
    "    for label, feature_vecs in dataset.items() :\n",
    "        for features in feature_vecs :\n",
    "            features_dataset.append(features)\n",
    "            label_dataset.append(label)\n",
    "\n",
    "    return np.array(features_dataset), np.array(label_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "ef2ef9f0-b235-4978-a284-5b2ff6e0ae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Joint test-train  Datasets combining all signals\n",
    "\n",
    "def get_agg_chest_signal_dataset(subjects) :\n",
    "    agg_feature_dataset = []\n",
    "    agg_labels_dataset = []\n",
    "    \n",
    "    for subject in subjects :\n",
    "        subject_data = read_subject_data(subject)\n",
    "        intervals = find_intervals(subject_data['label'])\n",
    "        \n",
    "        subject_agg = {\n",
    "            BASELINE : [],\n",
    "            STRESS : [],\n",
    "            AMUSEMENT : [],\n",
    "            MEDITATION : []\n",
    "        }\n",
    "        \n",
    "        for signal_type in CHEST_SIGNALS :\n",
    "            if signal_type == 'ACC' :\n",
    "                continue\n",
    "                \n",
    "            signal = np.array(subject_data['signal']['chest'][signal_type]).flatten()\n",
    "            signal_features = extract_signal_features(signal, intervals, CHEST_SAMPLING_RATE)\n",
    "            \n",
    "            for label, features in signal_features.items() :\n",
    "                subject_agg[label].append(features)\n",
    "                \n",
    "        for label in subject_agg :\n",
    "            subject_agg[label] = np.stack(subject_agg[label], axis = 1)\n",
    "            \n",
    "        for label, feature_aggs in subject_agg.items() :\n",
    "            for feature_agg in feature_aggs :\n",
    "                agg_feature_dataset.append(feature_agg)\n",
    "                agg_labels_dataset.append(label)\n",
    "\n",
    "    return agg_feature_dataset, agg_labels_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "0e394649-fb30-45d2-9fe6-2601fff98fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Datasets\n",
    "def visualize_dataset(features, labels) :\n",
    "    features = np.array(features)\n",
    "    amps = np.log10(features[:, :, 0].flatten())\n",
    "    freqs  = features[:, :, 1].flatten()\n",
    "    labels = np.repeat(np.array(labels), NUM_FEATURES)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['Amp'] = amps\n",
    "    df['Freq'] = freqs\n",
    "    df['Label'] = labels\n",
    "    \n",
    "    for label, group in df.groupby('Label') :\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        sns.scatterplot(x = 'Freq', y = 'Amp', data = group, palette='bright').set(title=label)\n",
    "    \n",
    "    plt.figure(figsize=(20, 20))\n",
    "    sns.scatterplot(x = 'Freq', y = 'Amp', hue = 'Label', style='Label', data = df, palette='bright')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51f2afa-6366-4d86-bf5b-14b1f8f3e40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ECG Test-Train Datasets\n",
    "\n",
    "TRAIN_TEST_RATIO = 0.1\n",
    "\n",
    "np.random.shuffle(SUBJECTS)\n",
    "num_subjects = len(SUBJECTS)\n",
    "k = int ((1 - TRAIN_TEST_RATIO) * num_subjects)\n",
    "\n",
    "train_features, train_labels = get_chest_signal_dataset(SUBJECTS[0 : k], 'EDA')\n",
    "test_features, test_labels = get_chest_signal_dataset(SUBJECTS[k : num_subjects], 'EDA')\n",
    "\n",
    "train_features, test_features = normalize_fft_features(train_features, test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "1b6f8d9f-a78a-44ee-a36d-86bae3b5eb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ECG Test-Train Datasets\n",
    "\n",
    "TRAIN_TEST_RATIO = 0.1\n",
    "\n",
    "np.random.shuffle(SUBJECTS)\n",
    "num_subjects = len(SUBJECTS)\n",
    "k = int ((1 - TRAIN_TEST_RATIO) * num_subjects)\n",
    "\n",
    "train_features, train_labels = get_agg_chest_signal_dataset(SUBJECTS[0 : k])\n",
    "test_features, test_labels = get_agg_chest_signal_dataset(SUBJECTS[k : num_subjects])\n",
    "train_features, test_features = normalize_fft_features(train_features, test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4e37c3-00d9-4696-86a9-080aa5e5d78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dataset(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3672f4-fc26-4d24-9cf5-1c4bd787417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dataset(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "689ceaff-e408-4f52-b408-6166932649be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(labels) :\n",
    "    encoder = {\n",
    "        1 : [1, 0, 0, 0],\n",
    "        2 : [0, 1, 0, 0],\n",
    "        3 : [0, 0, 1, 0],\n",
    "        4 : [0, 0, 0, 1]\n",
    "    }\n",
    "    \n",
    "    return np.array([np.array(encoder[l]) for l in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "79147376-30ab-4bf6-b8a0-d9f8df37a92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = encode_labels(train_labels)\n",
    "test_labels = encode_labels(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-given",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "8917fe46-4afc-465f-9ea2-c18ab3673abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(5, 10, 2)),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Conv2D(3, kernel_size=(2, 2), activation='swish'),\n",
    "    keras.layers.AveragePooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Dense(units=15,  activation='swish'),\n",
    "    keras.layers.Dense(units=10,  activation='swish'),\n",
    "    keras.layers.Conv2D(2, kernel_size=(1, 4), activation='swish'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=15,  activation='swish'),\n",
    "    keras.layers.Dense(units=8,  activation='swish'),\n",
    "    keras.layers.Dense(units=6,  activation='swish'),\n",
    "    keras.layers.Dense(units=6,  activation='swish'),\n",
    "    keras.layers.Dense(units=4)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "d966a479-0a9f-4de9-a737-a1772e0516e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_122 (Dropout)        (None, 5, 10, 2)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_139 (Conv2D)          (None, 4, 9, 3)           27        \n",
      "_________________________________________________________________\n",
      "average_pooling2d_45 (Averag (None, 2, 4, 3)           0         \n",
      "_________________________________________________________________\n",
      "dense_471 (Dense)            (None, 2, 4, 15)          60        \n",
      "_________________________________________________________________\n",
      "dense_472 (Dense)            (None, 2, 4, 10)          160       \n",
      "_________________________________________________________________\n",
      "conv2d_140 (Conv2D)          (None, 2, 1, 2)           82        \n",
      "_________________________________________________________________\n",
      "flatten_96 (Flatten)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_473 (Dense)            (None, 15)                75        \n",
      "_________________________________________________________________\n",
      "dense_474 (Dense)            (None, 8)                 128       \n",
      "_________________________________________________________________\n",
      "dense_475 (Dense)            (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_476 (Dense)            (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_477 (Dense)            (None, 4)                 28        \n",
      "=================================================================\n",
      "Total params: 656\n",
      "Trainable params: 656\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "fed147b0-c7b2-4eab-93ae-68183d56c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.losses.CategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "institutional-grade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "! rm -rf ./logs/\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "given-lewis",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "occupied-scheme",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e8bb6cdbe9214f3b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e8bb6cdbe9214f3b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "7f89e017-73d3-44fd-b7fc-f6782da8a1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7570, 5, 10, 2) (7570, 4) (1172, 5, 10, 2) (1172, 4)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(train_features), np.shape(train_labels), np.shape(test_features), np.shape(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "5bc53806-1ce8-4628-9f7d-42a7839ac126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.1443 - accuracy: 0.9467 - val_loss: 0.4649 - val_accuracy: 0.8734\n",
      "Epoch 2/20\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.1399 - accuracy: 0.9480 - val_loss: 0.6347 - val_accuracy: 0.8605\n",
      "Epoch 3/20\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.1367 - accuracy: 0.9499 - val_loss: 0.5492 - val_accuracy: 0.8708\n",
      "Epoch 4/20\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.1339 - accuracy: 0.9501 - val_loss: 0.5844 - val_accuracy: 0.8639\n",
      "Epoch 5/20\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.1333 - accuracy: 0.9515 - val_loss: 0.5188 - val_accuracy: 0.8674\n",
      "Epoch 6/20\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.1356 - accuracy: 0.9522 - val_loss: 0.4781 - val_accuracy: 0.8768\n",
      "Epoch 7/20\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.1329 - accuracy: 0.9529 - val_loss: 0.4952 - val_accuracy: 0.8682\n",
      "Epoch 8/20\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.1384 - accuracy: 0.9491 - val_loss: 0.5878 - val_accuracy: 0.8544\n",
      "Epoch 9/20\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.1422 - accuracy: 0.9455 - val_loss: 0.4937 - val_accuracy: 0.8691\n",
      "Epoch 10/20\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.1334 - accuracy: 0.9517 - val_loss: 0.5657 - val_accuracy: 0.8605\n",
      "Epoch 11/20\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.1361 - accuracy: 0.9504 - val_loss: 0.5994 - val_accuracy: 0.8648\n",
      "Epoch 12/20\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.1372 - accuracy: 0.9486 - val_loss: 0.5698 - val_accuracy: 0.8562\n",
      "Epoch 13/20\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.1415 - accuracy: 0.9474 - val_loss: 0.5567 - val_accuracy: 0.8648\n",
      "Epoch 14/20\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.1399 - accuracy: 0.9475 - val_loss: 0.5414 - val_accuracy: 0.8639\n",
      "Epoch 15/20\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.1419 - accuracy: 0.9488 - val_loss: 0.7118 - val_accuracy: 0.8475\n",
      "Epoch 16/20\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.1395 - accuracy: 0.9490 - val_loss: 0.5391 - val_accuracy: 0.8734\n",
      "Epoch 17/20\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.1423 - accuracy: 0.9468 - val_loss: 0.6275 - val_accuracy: 0.8622\n",
      "Epoch 18/20\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.1425 - accuracy: 0.9463 - val_loss: 0.5335 - val_accuracy: 0.8699\n",
      "Epoch 19/20\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.1336 - accuracy: 0.9495 - val_loss: 0.4745 - val_accuracy: 0.8691\n",
      "Epoch 20/20\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.1415 - accuracy: 0.9482 - val_loss: 0.4320 - val_accuracy: 0.8794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe57c267220>"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i = 0\n",
    "# while True :\n",
    "model.fit(train_features, train_labels, epochs=20, shuffle = True, verbose=1,\n",
    "          validation_data=(test_features,  test_labels), \n",
    "          callbacks=[tensorboard_callback])\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "defined-tenant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 - 0s - loss: 0.4320 - accuracy: 0.8794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43198782205581665, 0.8794143199920654]"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_features,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-syndicate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-hurricane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "train_features_file = open('train_features_file', 'wb')\n",
    "test_features_file = open('test_features_file', 'wb')\n",
    "train_labels_file = open('train_labels_file', 'wb')\n",
    "test_labels_file = open('test_labels_file', 'wb')\n",
    "\n",
    "pickle.dump(train_features, train_features_file)\n",
    "pickle.dump(test_features, test_features_file)\n",
    "pickle.dump(train_labels, train_labels_file)\n",
    "pickle.dump(test_labels, test_labels_file)\n",
    "\n",
    "train_features_file.close()\n",
    "test_features_file.close()\n",
    "train_labels_file.close()\n",
    "test_labels_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a68dccf-f2fc-415f-9b37-2bc0a97e0fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_features), len(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4089036b-5e32-4c8c-a2bb-8dd6a0b63063",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = np.array([[[1, 9], [3, 4], [10, 12]], [[5, 6], [7, 8], [13, 11]]])\n",
    "t2 = np.array([[2, 3], [3, 4]])\n",
    "\n",
    "t3 = np.max(t1, axis=0)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f3ca17-aaa4-4cd8-8a1c-d28937b819c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack([t1, t1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050380bc-c689-4313-be9e-b95108bb36d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(t1, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60f0bc3-f5dd-4169-88e6-65147e71f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(t1, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0c9c0c-e980-491b-a9d0-afb145d77ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b93574-d1b4-48e1-a6d4-8a248dd60ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1[:, :, 0].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadfccde-b0af-4d58-b982-8b25a6054bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = zip(*train_dataset.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4675e07-792c-47ca-9cbb-d67082f25725",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4d90ca-b8e8-428f-a17e-f87ae128d355",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBJECTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c559f9-1f8f-4cbe-917b-92574073c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbcbc94-1506-4c04-a4f5-b955b66e0de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46ebecc-4855-4cd7-a4af-ee7d67a22be9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
